{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ Unsupervised Learning ‚Äî Clustering (DBSCAN Focus)\n",
    "\n",
    "**Course:** CSC582 ‚Äî King Saud University \n",
    "**Reference:** Introduction to Machine Learning with Python ‚Äî Chapter 3 (pp. 168‚Äì207) \n",
    "**GitHub:** [ClusteringInDBSCAN](https://github.com/YOUR_USERNAME/ClusteringInDBSCAN)\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Outline\n",
    "1. **k-Means Clustering** ‚Äî basics & failure cases\n",
    "2. **Agglomerative Clustering** ‚Äî hierarchical approach & dendrograms\n",
    "3. **DBSCAN** ‚≠ê ‚Äî density-based clustering (our focus)\n",
    "4. **Comparing & Evaluating** ‚Äî ARI, Silhouette Score\n",
    "5. **Real-World Demo** ‚Äî Iris dataset with all three algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import make_blobs, make_moons, load_iris\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, silhouette_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import dendrogram, ward\n",
    "\n",
    "# Plot style\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print('All imports successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. k-Means Clustering (pp. 168‚Äì181)\n",
    "\n",
    "**How it works:**\n",
    "1. Choose k (number of clusters)\n",
    "2. Randomly initialize k cluster centers\n",
    "3. Assign each point to the nearest center\n",
    "4. Recompute centers as the mean of assigned points\n",
    "5. Repeat 3‚Äì4 until convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Basic k-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic 2D data with 3 blobs\n",
    "X, y_true = make_blobs(n_samples=300, centers=3, random_state=1, cluster_std=0.60)\n",
    "\n",
    "# Apply k-Means\n",
    "kmeans = KMeans(n_clusters=3, random_state=0, n_init=10)\n",
    "kmeans.fit(X)\n",
    "\n",
    "print(f'Cluster labels (first 20): {kmeans.labels_[:20]}')\n",
    "print(f'Cluster centers:\\n{kmeans.cluster_centers_}')\n",
    "print(f'Inertia (sum of squared distances): {kmeans.inertia_:.2f}')\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].scatter(X[:, 0], X[:, 1], c=y_true, cmap='viridis', s=40, alpha=0.7)\n",
    "axes[0].set_title('Original Data (True Labels)', fontsize=14)\n",
    "axes[0].set_xlabel('Feature 0'); axes[0].set_ylabel('Feature 1')\n",
    "\n",
    "axes[1].scatter(X[:, 0], X[:, 1], c=kmeans.labels_, cmap='viridis', s=40, alpha=0.7)\n",
    "axes[1].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "                c='red', marker='^', s=200, edgecolors='black', linewidth=2,\n",
    "                label='Cluster Centers')\n",
    "axes[1].set_title('k-Means Clustering (k=3)', fontsize=14)\n",
    "axes[1].set_xlabel('Feature 0'); axes[1].set_ylabel('Feature 1')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Elbow Method ‚Äî Choosing Optimal k *(Enhancement)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = []\n",
    "sil_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=0, n_init=10)\n",
    "    km.fit(X)\n",
    "    inertias.append(km.inertia_)\n",
    "    sil_scores.append(silhouette_score(X, km.labels_))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Number of Clusters (k)'); axes[0].set_ylabel('Inertia')\n",
    "axes[0].set_title('Elbow Method', fontsize=14)\n",
    "axes[0].axvline(x=3, color='red', linestyle='--', alpha=0.7, label='Optimal k=3')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(K_range, sil_scores, 'go-', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Number of Clusters (k)'); axes[1].set_ylabel('Silhouette Score')\n",
    "axes[1].set_title('Silhouette Score vs k', fontsize=14)\n",
    "axes[1].axvline(x=3, color='red', linestyle='--', alpha=0.7, label='Optimal k=3')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('The elbow at k=3 confirms the optimal number of clusters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 k-Means Failure Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Case 1: Different densities\n",
    "X_varied, y_varied = make_blobs(n_samples=200, cluster_std=[1.0, 2.5, 0.5], random_state=170)\n",
    "y_pred = KMeans(n_clusters=3, random_state=0, n_init=10).fit_predict(X_varied)\n",
    "axes[0].scatter(X_varied[:, 0], X_varied[:, 1], c=y_pred, cmap='viridis', s=40)\n",
    "axes[0].set_title('Failure: Different Densities', fontsize=13)\n",
    "\n",
    "# Case 2: Non-spherical / elongated clusters\n",
    "X_blob, y_blob = make_blobs(random_state=170, n_samples=600)\n",
    "rng = np.random.RandomState(74)\n",
    "transformation = rng.normal(size=(2, 2))\n",
    "X_aniso = np.dot(X_blob, transformation)\n",
    "y_pred2 = KMeans(n_clusters=3, random_state=0, n_init=10).fit_predict(X_aniso)\n",
    "axes[1].scatter(X_aniso[:, 0], X_aniso[:, 1], c=y_pred2, cmap='viridis', s=40)\n",
    "axes[1].set_title('Failure: Non-Spherical Clusters', fontsize=13)\n",
    "\n",
    "# Case 3: Two moons (complex shapes)\n",
    "X_moons, y_moons = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "y_pred3 = KMeans(n_clusters=2, random_state=0, n_init=10).fit_predict(X_moons)\n",
    "axes[2].scatter(X_moons[:, 0], X_moons[:, 1], c=y_pred3, cmap='viridis', s=40)\n",
    "axes[2].set_title('Failure: Complex Shapes (Two Moons)', fontsize=13)\n",
    "\n",
    "plt.suptitle('k-Means Failure Cases', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Agglomerative Clustering (pp. 182‚Äì187)\n",
    "\n",
    "**How it works (bottom-up):**\n",
    "1. Each point starts as its own cluster\n",
    "2. Find the two most similar (closest) clusters\n",
    "3. Merge them into one\n",
    "4. Repeat until desired number of clusters reached\n",
    "\n",
    "**Linkage criteria:** Ward (default), Average, Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agg, y_agg = make_blobs(random_state=1)\n",
    "\n",
    "agg = AgglomerativeClustering(n_clusters=3)\n",
    "assignment = agg.fit_predict(X_agg)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_agg[:, 0], X_agg[:, 1], c=assignment, cmap='viridis', s=60,\n",
    "            edgecolors='black', linewidth=0.5)\n",
    "plt.xlabel('Feature 0'); plt.ylabel('Feature 1')\n",
    "plt.title('Agglomerative Clustering (Ward Linkage, 3 Clusters)', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dendro, y_dendro = make_blobs(random_state=0, n_samples=12)\n",
    "linkage_array = ward(X_dendro)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "dendrogram(linkage_array)\n",
    "\n",
    "ax = plt.gca()\n",
    "bounds = ax.get_xbound()\n",
    "ax.plot(bounds, [7.25, 7.25], '--', c='red', linewidth=2)\n",
    "ax.plot(bounds, [4, 4], '--', c='blue', linewidth=2)\n",
    "ax.text(bounds[1], 7.25, '  2 clusters', va='center', fontsize=13, color='red')\n",
    "ax.text(bounds[1], 4, '  3 clusters', va='center', fontsize=13, color='blue')\n",
    "\n",
    "plt.xlabel('Sample Index'); plt.ylabel('Cluster Distance (Ward)')\n",
    "plt.title('Dendrogram ‚Äî Hierarchical Clustering', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚≠ê 3. DBSCAN ‚Äî Density-Based Clustering (pp. 187‚Äì190)\n",
    "\n",
    "**Key advantages over k-Means and Agglomerative:**\n",
    "- Does NOT require specifying number of clusters\n",
    "- Handles complex, non-convex shapes\n",
    "- Detects noise/outliers automatically\n",
    "\n",
    "**Two parameters:**\n",
    "- `eps` ‚Äî radius of neighborhood around each point\n",
    "- `min_samples` ‚Äî minimum neighbors to be a core point\n",
    "\n",
    "**Three point types:**\n",
    "- **Core** ‚Äî ‚â• min_samples neighbors within eps (heart of cluster)\n",
    "- **Border** ‚Äî < min_samples neighbors, but within eps of a core point (edge of cluster)\n",
    "- **Noise** ‚Äî not near any core point ‚Üí label = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 DBSCAN Parameter Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_db, y_db = make_blobs(random_state=0, n_samples=12)\n",
    "\n",
    "print('Effect of eps and min_samples on clustering:')\n",
    "print(f'{\"min_samples\":>12} {\"eps\":>6} {\"clusters\":>40}')\n",
    "print('-' * 62)\n",
    "\n",
    "for min_s in [2, 3, 5]:\n",
    "    for eps_val in [1.0, 1.5, 2.0, 3.0]:\n",
    "        db = DBSCAN(min_samples=min_s, eps=eps_val)\n",
    "        clusters = db.fit_predict(X_db)\n",
    "        print(f'{min_s:>12} {eps_val:>6.1f} {str(clusters):>40}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Effect of `eps` Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_moons, y_moons = make_moons(n_samples=300, noise=0.06, random_state=0)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_moons)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 11))\n",
    "eps_values = [0.1, 0.2, 0.3, 0.5, 0.8, 1.5]\n",
    "\n",
    "for ax, eps_val in zip(axes.ravel(), eps_values):\n",
    "    db = DBSCAN(eps=eps_val, min_samples=5)\n",
    "    labels = db.fit_predict(X_scaled)\n",
    "    \n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = list(labels).count(-1)\n",
    "    \n",
    "    # Noise in red\n",
    "    noise_mask = labels == -1\n",
    "    ax.scatter(X_scaled[noise_mask, 0], X_scaled[noise_mask, 1],\n",
    "               c='red', marker='x', s=50, label=f'Noise ({n_noise} pts)', zorder=3)\n",
    "    # Cluster points\n",
    "    cluster_mask = labels != -1\n",
    "    if cluster_mask.any():\n",
    "        ax.scatter(X_scaled[cluster_mask, 0], X_scaled[cluster_mask, 1],\n",
    "                   c=labels[cluster_mask], cmap='viridis', s=40,\n",
    "                   edgecolors='black', linewidth=0.3)\n",
    "    \n",
    "    # Show eps radius circle\n",
    "    if eps_val <= 0.5:\n",
    "        circle = plt.Circle((X_scaled[150, 0], X_scaled[150, 1]),\n",
    "                           eps_val, fill=False, color='red', linewidth=2,\n",
    "                           linestyle='--', alpha=0.7)\n",
    "        ax.add_patch(circle)\n",
    "        ax.plot(X_scaled[150, 0], X_scaled[150, 1], 'r*', markersize=15, zorder=5)\n",
    "    \n",
    "    if n_clusters == 0: result, color = 'ALL NOISE!', 'red'\n",
    "    elif n_clusters == 2: result, color = 'CORRECT!', 'green'\n",
    "    elif n_clusters == 1: result, color = 'One big cluster', 'orange'\n",
    "    else: result, color = 'Too fragmented', 'orange'\n",
    "    \n",
    "    ax.set_title(f'eps = {eps_val}\\n{n_clusters} clusters, {n_noise} noise ‚Äî {result}',\n",
    "                fontsize=13, fontweight='bold', color=color)\n",
    "    ax.set_xlabel('Feature 0'); ax.set_ylabel('Feature 1')\n",
    "    ax.legend(loc='upper right', fontsize=9)\n",
    "\n",
    "fig.suptitle('EFFECT OF eps (min_samples fixed at 5)\\n'\n",
    "             'Red dashed circle = eps neighborhood radius',\n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Effect of `min_samples` Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 11))\n",
    "min_samples_values = [2, 3, 5, 10, 20, 50]\n",
    "\n",
    "for ax, min_s in zip(axes.ravel(), min_samples_values):\n",
    "    db = DBSCAN(eps=0.5, min_samples=min_s)\n",
    "    labels = db.fit_predict(X_scaled)\n",
    "    \n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = list(labels).count(-1)\n",
    "    \n",
    "    # Identify point types\n",
    "    core_mask = np.zeros(len(labels), dtype=bool)\n",
    "    if hasattr(db, 'core_sample_indices_') and len(db.core_sample_indices_) > 0:\n",
    "        core_mask[db.core_sample_indices_] = True\n",
    "    \n",
    "    noise_mask = labels == -1\n",
    "    border_mask = (labels != -1) & (~core_mask)\n",
    "    \n",
    "    # Plot noise\n",
    "    ax.scatter(X_scaled[noise_mask, 0], X_scaled[noise_mask, 1],\n",
    "               c='red', marker='x', s=50, label=f'Noise ({n_noise})', zorder=3)\n",
    "    # Plot border (small)\n",
    "    if border_mask.any():\n",
    "        ax.scatter(X_scaled[border_mask, 0], X_scaled[border_mask, 1],\n",
    "                   c=labels[border_mask], cmap='viridis', s=30,\n",
    "                   edgecolors='black', linewidth=0.3, alpha=0.6)\n",
    "    # Plot core (large)\n",
    "    if core_mask.any():\n",
    "        ax.scatter(X_scaled[core_mask, 0], X_scaled[core_mask, 1],\n",
    "                   c=labels[core_mask], cmap='viridis', s=60,\n",
    "                   edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    n_core = core_mask.sum()\n",
    "    n_border = border_mask.sum()\n",
    "    ax.set_title(f'min_samples = {min_s}\\n{n_clusters} clusters | '\n",
    "                f'Core: {n_core} | Border: {n_border} | Noise: {n_noise}',\n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Feature 0'); ax.set_ylabel('Feature 1')\n",
    "    ax.legend(loc='upper right', fontsize=9)\n",
    "\n",
    "fig.suptitle('EFFECT OF min_samples (eps fixed at 0.5)\\n'\n",
    "             'Large dots = Core | Small dots = Border | Red X = Noise',\n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 DBSCAN vs k-Means vs Agglomerative on Two Moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_moons, y_moons = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "scaler = StandardScaler()\n",
    "X_moons_scaled = scaler.fit_transform(X_moons)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# k-Means (fails)\n",
    "labels_km = KMeans(n_clusters=2, random_state=0, n_init=10).fit_predict(X_moons_scaled)\n",
    "axes[0].scatter(X_moons_scaled[:, 0], X_moons_scaled[:, 1], c=labels_km, cmap='viridis', s=60)\n",
    "axes[0].set_title('k-Means (k=2)\\n‚ùå Fails on complex shapes!', fontsize=13)\n",
    "\n",
    "# Agglomerative (fails)\n",
    "labels_agg = AgglomerativeClustering(n_clusters=2).fit_predict(X_moons_scaled)\n",
    "axes[1].scatter(X_moons_scaled[:, 0], X_moons_scaled[:, 1], c=labels_agg, cmap='viridis', s=60)\n",
    "axes[1].set_title('Agglomerative (k=2)\\n‚ùå Also fails!', fontsize=13)\n",
    "\n",
    "# DBSCAN (succeeds!)\n",
    "labels_db = DBSCAN(eps=0.5, min_samples=5).fit_predict(X_moons_scaled)\n",
    "axes[2].scatter(X_moons_scaled[:, 0], X_moons_scaled[:, 1], c=labels_db, cmap='viridis', s=60)\n",
    "axes[2].set_title('DBSCAN (eps=0.5)\\n‚úÖ Correctly separates!', fontsize=13)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Feature 0'); ax.set_ylabel('Feature 1')\n",
    "\n",
    "plt.suptitle('Two Moons: DBSCAN Succeeds Where Others Fail', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 DBSCAN Core / Border / Noise Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with visible noise points\n",
    "X_demo, y_demo = make_moons(n_samples=200, noise=0.12, random_state=42)\n",
    "scaler_demo = StandardScaler()\n",
    "X_demo_scaled = scaler_demo.fit_transform(X_demo)\n",
    "\n",
    "db_demo = DBSCAN(eps=0.4, min_samples=5)\n",
    "labels_demo = db_demo.fit_predict(X_demo_scaled)\n",
    "\n",
    "core_mask = np.zeros(len(labels_demo), dtype=bool)\n",
    "core_mask[db_demo.core_sample_indices_] = True\n",
    "noise_mask = labels_demo == -1\n",
    "border_mask = (~core_mask) & (~noise_mask)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "# Core points (large circles)\n",
    "ax.scatter(X_demo_scaled[core_mask, 0], X_demo_scaled[core_mask, 1],\n",
    "           c=labels_demo[core_mask], cmap='viridis', s=100,\n",
    "           edgecolors='black', linewidth=1,\n",
    "           label=f'Core Points ({core_mask.sum()})', zorder=3)\n",
    "\n",
    "# Border points (small squares)\n",
    "ax.scatter(X_demo_scaled[border_mask, 0], X_demo_scaled[border_mask, 1],\n",
    "           c=labels_demo[border_mask], cmap='viridis', s=50,\n",
    "           edgecolors='gray', linewidth=1, marker='s',\n",
    "           label=f'Border Points ({border_mask.sum()})', zorder=2)\n",
    "\n",
    "# Noise points (red X)\n",
    "ax.scatter(X_demo_scaled[noise_mask, 0], X_demo_scaled[noise_mask, 1],\n",
    "           c='red', s=80, marker='X', linewidth=1,\n",
    "           label=f'Noise Points ({noise_mask.sum()})', zorder=4)\n",
    "\n",
    "# Draw eps circles around two core points\n",
    "for idx in db_demo.core_sample_indices_[:2]:\n",
    "    circle = plt.Circle((X_demo_scaled[idx, 0], X_demo_scaled[idx, 1]),\n",
    "                       0.4, fill=False, color='blue', linewidth=1.5,\n",
    "                       linestyle='--', alpha=0.5)\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "ax.set_xlabel('Feature 0', fontsize=13); ax.set_ylabel('Feature 1', fontsize=13)\n",
    "ax.set_title('DBSCAN Point Types (eps=0.4, min_samples=5)\\n'\n",
    "             'Blue dashed circles = eps neighborhood',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=12, loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Comparing & Evaluating Clustering (pp. 191‚Äì207)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Adjusted Rand Index (ARI) ‚Äî With Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval, y_eval = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "scaler = StandardScaler()\n",
    "X_eval_scaled = scaler.fit_transform(X_eval)\n",
    "\n",
    "random_state = np.random.RandomState(seed=0)\n",
    "random_clusters = random_state.randint(low=0, high=2, size=len(X_eval))\n",
    "\n",
    "algorithms = {\n",
    "    'Random': random_clusters,\n",
    "    'k-Means': KMeans(n_clusters=2, random_state=0, n_init=10).fit_predict(X_eval_scaled),\n",
    "    'Agglomerative': AgglomerativeClustering(n_clusters=2).fit_predict(X_eval_scaled),\n",
    "    'DBSCAN': DBSCAN().fit_predict(X_eval_scaled),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "\n",
    "print('ARI Scores (1.0 = perfect, 0.0 = random):')\n",
    "for ax, (name, labels) in zip(axes, algorithms.items()):\n",
    "    ari = adjusted_rand_score(y_eval, labels)\n",
    "    print(f'  {name:20s}: {ari:.2f}')\n",
    "    ax.scatter(X_eval_scaled[:, 0], X_eval_scaled[:, 1], c=labels, cmap='viridis', s=40)\n",
    "    ax.set_title(f'{name}\\nARI: {ari:.2f}', fontsize=12)\n",
    "\n",
    "plt.suptitle('Adjusted Rand Index (ARI) Comparison', fontsize=15, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Why accuracy_score is WRONG for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters1 = [0, 0, 1, 1, 0]\n",
    "clusters2 = [1, 1, 0, 0, 1]  # Same grouping, labels just swapped!\n",
    "\n",
    "print(f'Clusters1: {clusters1}')\n",
    "print(f'Clusters2: {clusters2}  (identical grouping, different labels)')\n",
    "print(f'\\nAccuracy:  {accuracy_score(clusters1, clusters2):.2f}  <-- WRONG! Says 0%')\n",
    "print(f'ARI:       {adjusted_rand_score(clusters1, clusters2):.2f}  <-- CORRECT! Says 100%')\n",
    "print('\\nLesson: Cluster labels are arbitrary. Always use ARI or NMI, never accuracy!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Silhouette Score ‚Äî Without Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "\n",
    "print('Silhouette Scores (higher = more compact clusters):')\n",
    "for ax, (name, labels) in zip(axes, algorithms.items()):\n",
    "    n_unique = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    sil = silhouette_score(X_eval_scaled, labels) if n_unique >= 2 else -1\n",
    "    print(f'  {name:20s}: {sil:.2f}')\n",
    "    ax.scatter(X_eval_scaled[:, 0], X_eval_scaled[:, 1], c=labels, cmap='viridis', s=40)\n",
    "    ax.set_title(f'{name}\\nSilhouette: {sil:.2f}', fontsize=12)\n",
    "\n",
    "plt.suptitle('Silhouette Score Comparison', fontsize=15, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('\\nNote: k-Means scores HIGHER than DBSCAN even though DBSCAN is visually correct!')\n",
    "print('Silhouette favors compact spherical clusters ‚Äî it can be misleading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Real-World Demo ‚Äî Iris Dataset *(Enhancement)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "print(f'Iris dataset: {X_iris.shape[0]} samples, {X_iris.shape[1]} features')\n",
    "print(f'Features: {iris.feature_names}')\n",
    "print(f'True classes: {iris.target_names}')\n",
    "\n",
    "# Scale and reduce to 2D for visualization\n",
    "scaler_iris = StandardScaler()\n",
    "X_iris_scaled = scaler_iris.fit_transform(X_iris)\n",
    "pca_iris = PCA(n_components=2)\n",
    "X_iris_2d = pca_iris.fit_transform(X_iris_scaled)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# True labels\n",
    "axes[0, 0].scatter(X_iris_2d[:, 0], X_iris_2d[:, 1], c=y_iris, cmap='viridis', s=50,\n",
    "                    edgecolors='black', linewidth=0.5)\n",
    "axes[0, 0].set_title('True Labels', fontsize=14)\n",
    "\n",
    "# k-Means\n",
    "labels_km = KMeans(n_clusters=3, random_state=0, n_init=10).fit_predict(X_iris_scaled)\n",
    "ari_km = adjusted_rand_score(y_iris, labels_km)\n",
    "axes[0, 1].scatter(X_iris_2d[:, 0], X_iris_2d[:, 1], c=labels_km, cmap='viridis', s=50,\n",
    "                    edgecolors='black', linewidth=0.5)\n",
    "axes[0, 1].set_title(f'k-Means (k=3) ‚Äî ARI: {ari_km:.2f}', fontsize=14)\n",
    "\n",
    "# Agglomerative\n",
    "labels_agg = AgglomerativeClustering(n_clusters=3).fit_predict(X_iris_scaled)\n",
    "ari_agg = adjusted_rand_score(y_iris, labels_agg)\n",
    "axes[1, 0].scatter(X_iris_2d[:, 0], X_iris_2d[:, 1], c=labels_agg, cmap='viridis', s=50,\n",
    "                    edgecolors='black', linewidth=0.5)\n",
    "axes[1, 0].set_title(f'Agglomerative ‚Äî ARI: {ari_agg:.2f}', fontsize=14)\n",
    "\n",
    "# DBSCAN\n",
    "labels_db = DBSCAN(eps=0.9, min_samples=5).fit_predict(X_iris_scaled)\n",
    "ari_db = adjusted_rand_score(y_iris, labels_db)\n",
    "n_noise = list(labels_db).count(-1)\n",
    "axes[1, 1].scatter(X_iris_2d[:, 0], X_iris_2d[:, 1], c=labels_db, cmap='viridis', s=50,\n",
    "                    edgecolors='black', linewidth=0.5)\n",
    "axes[1, 1].set_title(f'DBSCAN ‚Äî ARI: {ari_db:.2f} ({n_noise} noise pts)', fontsize=14)\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.set_xlabel('PCA Component 1'); ax.set_ylabel('PCA Component 2')\n",
    "\n",
    "plt.suptitle('Clustering Algorithms on Iris Dataset', fontsize=16, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Summary ‚Äî Algorithm Comparison\n",
    "\n",
    "| Feature | k-Means | Agglomerative | DBSCAN |\n",
    "|---------|---------|---------------|--------|\n",
    "| Must set # clusters | Yes | Yes | **No** |\n",
    "| Complex shapes | No | No | **Yes** |\n",
    "| Noise detection | No | No | **Yes** |\n",
    "| Scalability | Excellent | Good | Good |\n",
    "| Cluster sizes | Even | Even | Varies |\n",
    "| Interpretability | Cluster centers | Dendrogram | Core/border/noise |\n",
    "| Key parameters | n_clusters | n_clusters, linkage | eps, min_samples |"
   ]
  }
 ]
}
